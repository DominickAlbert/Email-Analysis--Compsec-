{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954456f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. \n",
      "\tInstead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: \n",
      "\tflwr.client.start_client(\n",
      "\t\tserver_address='<IP>:<PORT>',\n",
      "\t\tclient=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object\n",
      "\t)\n",
      "\tUsing `start_numpy_client()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.\n",
      "\tInstead, use the `flower-supernode` CLI command to start a SuperNode as shown below:\n",
      "\n",
      "\t\t$ flower-supernode --insecure --superlink='<IP>:<PORT>'\n",
      "\n",
      "\tTo view all available options, run:\n",
      "\n",
      "\t\t$ flower-supernode --help\n",
      "\n",
      "\tUsing `start_client()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      Received: get_parameters message 2394a249-fbba-4b2d-a6a9-78d4711db7c6\n"
     ]
    }
   ],
   "source": [
    "# client.py\n",
    "import flwr as fl\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import nltk\n",
    "from phe import paillier # Library for HE\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"<[^>]+>\", \"\", str(text))  \n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s\\-]\", \"\", text)  # Retain hyphens\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text, flags=re.UNICODE)  \n",
    "    text = [word.lower() for word in word_tokenize(text) if word.lower() not in stop_words]\n",
    "    return \" \".join(text).strip()  \n",
    "\n",
    "def preprocess_data(df):\n",
    "    # 1. prepare data\n",
    "    df[\"clean_subject\"] = df[\"subject\"].apply(clean_text)\n",
    "    df[\"clean_body\"] = df[\"body\"].apply(clean_text)\n",
    "\n",
    "    # Extract sender domain\n",
    "    df[\"sender_domain\"] = df[\"sender\"].apply(lambda x: x.split(\"@\")[-1] if pd.notnull(x) else \"\")\n",
    "    df['sender_domain'] = df['sender_domain'].str[:-1]\n",
    "\n",
    "    df[\"receiver_domain\"] = df[\"receiver\"].apply(lambda x: x.split(\"@\")[-1] if pd.notnull(x) else \"\")\n",
    "    # df['receiver_domain'] = df['receiver_domain'].str[:-1]\n",
    "    df['receiver_domain'] = df['receiver_domain'].apply(lambda x: x[:-1] if x.endswith(\">\") else x)\n",
    "\n",
    "    # Parse date (handle inconsistent formats)\n",
    "    df[\"date\"] = df[\"date\"].apply(lambda x: pd.to_datetime(x, errors=\"coerce\",utc = True))\n",
    "    df['hour'] = df['date'].dt.hour\n",
    "    df['day_of_week'] = df['date'].dt.dayofweek \n",
    "    df['hour_normalized'] = df['hour'] / 23.0\n",
    "\n",
    "    df = df.dropna(subset=[\"label\", \"clean_subject\", \"clean_body\",\"receiver\",\"subject\",\"date\"])\n",
    "\n",
    "    # Separate the majority and minority classes\n",
    "    majority_class = df[df['label'] == 1]\n",
    "    minority_class = df[df['label'] == 0]\n",
    "\n",
    "    # Randomly sample from the majority class to match the size of the minority class\n",
    "    balanced_majority_class = majority_class.sample(len(minority_class), random_state=42)\n",
    "\n",
    "    # Combine the balanced majority class with the minority class\n",
    "    df_balanced = pd.concat([balanced_majority_class, minority_class])\n",
    "\n",
    "    # Shuffle the resulting dataframe\n",
    "    df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    df_balanced['label'].value_counts()\n",
    "\n",
    "    df_balanced = df_balanced.drop(columns=[\"date\", \"sender\", \"receiver\", \"subject\", \"body\",\"hour\"])\n",
    "    # combine the subject and body for tfidf\n",
    "    df_balanced['subjectAndBody'] = df_balanced['clean_subject'] + ' ' + df_balanced['clean_body']\n",
    "\n",
    "    return df_balanced\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class SpamClient(fl.client.NumPyClient):\n",
    "    def __init__(self, df: pd.DataFrame, public_key):\n",
    "        self.public_key = public_key\n",
    "\n",
    "        #preprocess the data\n",
    "        df_clean = preprocess_data(df)\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            df_clean.drop(columns='label'), df_clean['label'], test_size=0.2, random_state=50\n",
    "        )\n",
    "        self.X_train_tfidif = vectorizer.fit_transform(X_train['subjectAndBody'])\n",
    "        self.X_test_tfidf = vectorizer.transform(X_test['subjectAndBody'])\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        self.vectorizer = vectorizer\n",
    "        self.df_clean = df_clean\n",
    "        # 2. initialize model\n",
    "        dummy_X = np.zeros((2, self.X_train_tfidif.shape[1]))\n",
    "        dummy_y = np.array([0, 1])\n",
    "        self.model = MultinomialNB()\n",
    "        self.model.partial_fit(dummy_X, dummy_y, classes=[0, 1])\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        # return Î¸: (feature_log_prob_, class_log_prior_)\n",
    "        feature_log_prob_encrypted = [self.public_key.encrypt(float(x)) for x in self.model.feature_log_prob_.flatten()]\n",
    "        class_log_prior_encrypted = [self.public_key.encrypt(float(x)) for x in self.model.class_log_prior_]\n",
    "        return [feature_log_prob_encrypted, class_log_prior_encrypted]\n",
    "\n",
    "    def set_parameters(self, parameters, config):\n",
    "        self.model.feature_log_prob_ = np.array([self.public_key.decrypt(x) for x in parameters[0]]).reshape(self.model.feature_log_prob_.shape)\n",
    "        self.model.class_log_prior_ = np.array([self.public_key.decrypt(x) for x in parameters[1]])\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        self.set_parameters(parameters, config)\n",
    "        self.model.partial_fit(self.X_train_tfidif, self.y_train, classes=[0,1])\n",
    "        return self.get_parameters(config), len(self.y_train), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        self.set_parameters(parameters, config)\n",
    "        loss = 1 - self.model.score(self.X_test_tfidf, self.y_test)\n",
    "        return loss, len(self.y_test), {\"accuracy\": self.model.score(self.X_test_tfidf, self.y_test)}\n",
    "\n",
    "# start client (pass in its local DataFrame)\n",
    "if __name__ == \"__main__\":\n",
    "    local_data = pd.read_csv(\"CEAS_08.csv\")\n",
    "    public_key,_ = paillier.generate_paillier_keypair()\n",
    "    client = SpamClient(local_data,public_key)\n",
    "    fl.client.start_numpy_client(server_address=\"localhost:8080\", client=client)\n",
    "\n",
    "    # Create a LIME explainer\n",
    "    pipeline = make_pipeline(client.vectorizer, client.model)\n",
    "    explainer = LimeTextExplainer(class_names=[\"safe\", \"phising\"])\n",
    "\n",
    "    # Choose a sample text to explain\n",
    "    sample_idx = 0\n",
    "    sample_text = client.df_clean['subjectAndBody'].iloc[0]\n",
    "\n",
    "    # Explain the prediction\n",
    "    exp = explainer.explain_instance(sample_text, pipeline.predict_proba, num_features=10)\n",
    "    print(f\"\\nExplaining prediction for:\\n{sample_text}\\n\")\n",
    "    exp.show_in_notebook()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
